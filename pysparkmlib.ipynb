{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(\"C:/dataanalytics/python\")\n",
    "os.curdir\n",
    "\n",
    "#Configure the environment . Set this up to the directory where spark is installed\n",
    "if 'SPARK_HOME' not in os.environ:\n",
    "    os.environ['SPARK_HOME'] = 'C:\\\\spark'\n",
    "    \n",
    "#create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. Please check your installation\n",
    "#to make sure that these zip files actually exists. The names might change as\n",
    "#versions change\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.6-src.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    " \n",
    "#Initialize a spark context\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "#optionally configure spark\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"Jeffwiz\")\n",
    "\n",
    "#Initalize spark context onl runs once\n",
    "sc = SparkContext('local', conf=conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.classification import LogisticRegressionModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.classification import SVMModel\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.mllib.clustering import BisectingKMeans\n",
    "from pyspark.mllib.classification import StreamingLogisticRegressionWithSGD\n",
    "from pyspark.mllib.clustering import GaussianMixture\n",
    "from pyspark.mllib.clustering import PowerIterationClustering\n",
    "from pyspark.mllib.clustering import StreamingKMeans\n",
    "from pyspark.mllib.clustering import LDA\n",
    "#one for from pyspark.mllib.evaluation BinaryClassificationMetrics\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "from pyspark.mllib.feature import ChiSqSelector\n",
    "from pyspark.mllib.feature import ElementwiseProduct\n",
    "from pyspark.mllib.fpm import PrefixSpan\n",
    "from pyspark.mllib.linalg import Matrix\n",
    "from pyspark.mllib.linalg import SparseMatrix\n",
    "from pyspark.mllib.linalg import QRDecomposition\n",
    "#for distributed matrixes check version\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "from pyspark.mllib.regression import RidgeRegressionModel\n",
    "from pyspark.mllib.regression import LassoModel\n",
    "from pyspark.mllib.regression import IsotonicRegression\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.tree import GradientBoostedTrees\n",
    "from pyspark.mllib.util import JavaLoader\n",
    "from pyspark.mllib.util import LinearDataGenerator\n",
    "from pyspark.mllib.util import Loader\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 0 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 4.745052855503306\n",
      "1 \t 0 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 2.52078447201548 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "0 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n",
      "1 \t 0 \t 2.52078447201548 \t 0\n",
      "1 \t 2.857738033247042 \t 0 \t 0\n"
     ]
    }
   ],
   "source": [
    "svmdata = sc.textFile(r'C:\\spark\\data\\mllib\\sample_svm_data.txt')\n",
    "rows = svmdata.map(lambda line:line.split(\" \"))\n",
    "for row in rows.take(rows.count()):print(row[0],'\\t',row[1],'\\t',row[2], '\\t', row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(r\"C\\spark\\mllib\\sample_svm_data.txt\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = SVMWithSGD.train(parsedData, iterations=100)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\n",
    "print(\"Training Error = \" + str(trainErr))\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, \"target/tmp/pythonSVMWithSGDModel\")\n",
    "sameModel = SVMModel.load(sc, \"target/tmp/pythonSVMWithSGDModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = iris.map(lambda line:line.split(\",\"))\n",
    "irisdatatrain = rows.map(lambda iris:labeledpoint(iris[4],iris[:3]))\n",
    "#spliiting the data\n",
    "iristrain, iristest = randomsplit(0.75,0.25)\n",
    "model = logisticregressionithlbfgs.train(iristrain)\n",
    "model.predict(iristest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to determne the number or rows\n",
    "iris = sc.textFile(r'C:\\Users\\jeffnerd\\Desktop\\IRIS.csv')\n",
    "rows = iris.map(lambda line:line.split(\",\"))\n",
    "for row in rows.take(rows.count()):\n",
    "    print(row[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(r\"C:\\spark\\mllib\\sample_svm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(r\"C:\\spark\\data\\mllib\\sample_svm_data.txt\")\n",
    "parsedData = data.map(parsePoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #Build the model\n",
    "model = SVMWithSGD.train(parsedData, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.38198757763975155\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.36645962732919257\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression model\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(r\"C:\\spark\\data\\mllib\\sample_svm_data.txt\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = LogisticRegressionWithLBFGS.train(parsedData, iterations=100)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\n",
    "print(\"Training Error = \" + str(trainErr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1), (0.0, 1), (0.0, 0), (1.0, 1), (1.0, 0), (0.0, 1), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (1.0, 1), (1.0, 0), (1.0, 0), (1.0, 0), (0.0, 0), (0.0, 1), (0.0, 0), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (0.0, 1), (1.0, 1), (0.0, 1), (1.0, 1), (1.0, 1), (0.0, 1), (1.0, 0), (0.0, 0), (1.0, 1), (0.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (0.0, 1), (1.0, 1), (0.0, 0), (0.0, 1), (1.0, 1), (1.0, 1), (0.0, 1), (1.0, 1), (0.0, 0), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 0), (1.0, 1), (0.0, 1), (0.0, 1), (0.0, 0), (1.0, 0), (1.0, 1), (0.0, 0), (0.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 1), (0.0, 1), (1.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 1), (1.0, 0), (1.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (1.0, 1), (0.0, 0), (1.0, 1), (1.0, 1), (0.0, 1), (0.0, 0), (1.0, 0), (0.0, 1), (1.0, 0), (0.0, 0), (1.0, 1), (1.0, 1), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (0.0, 0), (1.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (1.0, 1), (1.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 0), (0.0, 1), (0.0, 0), (1.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 1), (1.0, 0), (0.0, 1), (1.0, 1), (0.0, 1), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 0), (0.0, 1), (0.0, 0), (0.0, 1), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 0), (0.0, 0), (1.0, 0), (0.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (0.0, 1), (1.0, 0), (0.0, 1), (0.0, 1), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 1), (0.0, 1), (1.0, 1), (1.0, 0), (0.0, 0), (0.0, 1), (1.0, 1), (0.0, 1), (1.0, 1), (0.0, 1), (1.0, 1), (0.0, 0), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 1), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (1.0, 1), (1.0, 0), (1.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 0), (0.0, 1), (0.0, 0), (1.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (1.0, 0), (0.0, 0), (0.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (0.0, 1), (0.0, 1), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (0.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 1), (1.0, 0), (0.0, 1), (0.0, 0), (0.0, 1), (1.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 1), (0.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (1.0, 1), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 0), (0.0, 1), (1.0, 1), (0.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (1.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (1.0, 1), (0.0, 0), (1.0, 1), (1.0, 1), (1.0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(labelsAndPreds.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 0),\n",
       " (0.0, 1),\n",
       " (1.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (0.0, 0),\n",
       " (1.0, 1),\n",
       " (1.0, 1),\n",
       " (1.0, 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPreds.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 1.0, 2: 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vectors.sparse(4, [0,2], [1.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
